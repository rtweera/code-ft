{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "390f1c7c",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7591fd",
   "metadata": {},
   "source": [
    "This is a simulation of the tokenization process. The goal is to take a string of text and break it down into smaller pieces, or tokens. This is often the first step in natural language processing (NLP) tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9926eab",
   "metadata": {},
   "source": [
    "### Input sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a318fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Life is short, eat dessert first'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f0b58",
   "metadata": {},
   "source": [
    "### Simulating the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c543ffa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}\n"
     ]
    }
   ],
   "source": [
    "vocabulary = {s:i for i,s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b87e46e",
   "metadata": {},
   "source": [
    "### Tokenization Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca95c70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 4, 5, 2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sentence_int = torch.tensor([vocabulary[s] for s in sentence.replace(',', '').split()])\n",
    "print(sentence_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7611bc84",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffc2e14",
   "metadata": {},
   "source": [
    "Create vector embeddings for the tokens. Each token is represented as a 16-dimensional vector. Since we have 6 tokens, we will create a 6x16 matrix. The values in the matrix are randomly generated for the purpose of this simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,\n",
      "          0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951,  0.4954,  0.2692],\n",
      "        [ 0.5146,  0.9938, -0.2587, -1.0826, -0.0444,  1.6236, -2.3229,  1.0878,\n",
      "          0.6716,  0.6933, -0.9487, -0.0765, -0.1526,  0.1167,  0.4403, -1.4465],\n",
      "        [ 0.2553, -0.5496,  1.0042,  0.8272, -0.3948,  0.4892, -0.2168, -1.7472,\n",
      "         -1.6025, -1.0764,  0.9031, -0.7218, -0.5951, -0.7112,  0.6230, -1.3729],\n",
      "        [-1.3250,  0.1784, -2.1338,  1.0524, -0.3885, -0.9343, -0.4991, -1.0867,\n",
      "          0.8805,  1.5542,  0.6266, -0.1755,  0.0983, -0.0935,  0.2662, -0.5850],\n",
      "        [-0.0770, -1.0205, -0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010,\n",
      "          0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255, -0.6315, -2.8400],\n",
      "        [ 0.8768,  1.6221, -1.4779,  1.1331, -1.2203,  1.3139,  1.0533,  0.1388,\n",
      "          2.2473, -0.8036, -0.2808,  0.7697, -0.6596, -0.7979,  0.1838,  0.2293]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,\n",
      "          0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951,  0.4954,  0.2692],\n",
      "        [ 0.5146,  0.9938, -0.2587, -1.0826, -0.0444,  1.6236, -2.3229,  1.0878,\n",
      "          0.6716,  0.6933, -0.9487, -0.0765, -0.1526,  0.1167,  0.4403, -1.4465],\n",
      "        [ 0.2553, -0.5496,  1.0042,  0.8272, -0.3948,  0.4892, -0.2168, -1.7472,\n",
      "         -1.6025, -1.0764,  0.9031, -0.7218, -0.5951, -0.7112,  0.6230, -1.3729],\n",
      "        [-1.3250,  0.1784, -2.1338,  1.0524, -0.3885, -0.9343, -0.4991, -1.0867,\n",
      "          0.8805,  1.5542,  0.6266, -0.1755,  0.0983, -0.0935,  0.2662, -0.5850],\n",
      "        [-0.0770, -1.0205, -0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010,\n",
      "          0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255, -0.6315, -2.8400],\n",
      "        [ 0.8768,  1.6221, -1.4779,  1.1331, -1.2203,  1.3139,  1.0533,  0.1388,\n",
      "          2.2473, -0.8036, -0.2808,  0.7697, -0.6596, -0.7979,  0.1838,  0.2293]])\n",
      "torch.Size([6, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)  # embedding initialization is random, so we set a seed for reproducibility\n",
    "embed = torch.nn.Embedding(6, 16)  # 6 embeddings, 16 dimensions each\n",
    "embedded_sentence = embed(sentence_int).detach()    # detach() to avoid tracking gradients for this example (i.e. we are not training the embedding)\n",
    "\n",
    "print(embedded_sentence)\n",
    "print(embedded_sentence.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2095ef2f",
   "metadata": {},
   "source": [
    "# Q, K, V matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a6f7a6",
   "metadata": {},
   "source": [
    "Q = Query matrix\n",
    "K = Key matrix\n",
    "V = Value matrix\n",
    "\n",
    "For each token, we calculate the Q, K, V matrices. \n",
    "\n",
    "The Q (Query) and K (Key) matrices are used together to compute the attention scores (typically through a dot product), which are then passed through a softmax to get the attention weights. These weights are then used to weight the V (Value) matrix to produce the output of the attention mechanism.\n",
    "\n",
    "So in short:\n",
    "- Q and K → compute attention scores\n",
    "\n",
    "- Scores + softmax → attention weights\n",
    "\n",
    "- Attention weights × V → attention output\n",
    "\n",
    "For each token x_i, we calculate the Q, K, V matrices as follows:\n",
    "- q_i = Q * x_i\n",
    "- k_i = K * x_i\n",
    "- v_i = V * x_i\n",
    "\n",
    "Note that the Q, K matrices are size d_k x 16 and the V matrix is size d_v x 16."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea43862",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1767c694",
   "metadata": {},
   "source": [
    "## Q, K, V Analogy – Like a Search Engine \n",
    "\n",
    "- **Query (Q):** The user's search input (e.g., `\"cats\"`).\n",
    "- **Key (K):** The tags or keywords describing each document (e.g., `\"cat\"`, `\"animal\"`, `\"pet\"`).\n",
    "- **Value (V):** The actual content or data in the documents (e.g., the full article about cats).\n",
    "- **Attention Mechanism:** The model compares the **query** to all **keys** to determine **how relevant** each document is (attention weights), and then uses those weights to **focus on and combine** the corresponding **values** to generate the output.\n",
    "\n",
    "## Why Q, K, V called projection matrices?\n",
    "\n",
    "Because in linear algebra:\n",
    "> A projection is a transformation from one vector space to another, often used to extract certain features or views of the original data.\n",
    "\n",
    "Here, Q, K, and V each give a different \"view\" or role of the same input:\n",
    "\n",
    "- Q is for asking questions\n",
    "\n",
    "- K is for providing content descriptions (like metadata)\n",
    "\n",
    "- V is for carrying actual content\n",
    "\n",
    "The idea is: \"Let’s take the same input and linearly project it into three different functional spaces for computing attention.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d768a882",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d63c8b9",
   "metadata": {},
   "source": [
    "## Self-Attention Mechanism\n",
    "\n",
    "**Self-attention** is attending to the same text for context.\n",
    "\n",
    "`sentence` = \"Black cat sat on the brown mat.\"\n",
    "\n",
    "`tokens` = [\"Black\", \"cat\", \"sat\", \"on\", \"the\", \"brown\", \"mat\"]\n",
    "\n",
    "### Self-attention - let's focus on the word: \"black\"\n",
    "1. \"black\" becomes the Query (q)\n",
    "It asks: \"What words are important to me?\"\n",
    "\n",
    "2. It compares itself to every Key:\n",
    "    - Similarity(q<sub>black</sub>, K<sub>black</sub>)\n",
    "\n",
    "    - Similarity(q<sub>black</sub>, K<sub>cat</sub>)\n",
    "\n",
    "    - Similarity(q<sub>black</sub>, k<sub>sat</sub>)\n",
    "\n",
    "    - …and so on\n",
    "\n",
    "> **Note:** The similarity is often computed using a dot product or cosine similarity which gives a single value score for each pair of `q` and `k`. This score indicates how much attention the word \"black\" should pay to each of the other words in the sentence.\n",
    "\n",
    "3. Then softmax is applied to turn these scores into attention weights (probabilities).\n",
    "Let’s say after softmax, the query \"black\" gives highest weight to following keys:\n",
    "\n",
    "    - \"black\" itself → 0.5\n",
    "\n",
    "    - \"cat\" → 0.4\n",
    "\n",
    "    - others → 0.1 or less\n",
    "\n",
    "4. Use those weights on the Value vectors:\n",
    "    - 0.5 × v<sub>black</sub>\n",
    "\n",
    "    - 0.4 × v<sub>cat</sub>\n",
    "\n",
    "    - ... and so on\n",
    "\n",
    "- Add them up = the new vector representing \"black\" after attending to relevant context.\n",
    "\n",
    "> **Note:** The value vector `v` is the actual content of the words represented in a high-dimensional space.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a445fb9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e7e0b",
   "metadata": {},
   "source": [
    "We are calculating dot product between q_i and k_j for all i, j. Hence d_q = d_k = 24. \n",
    "\n",
    "Using d_v = 28."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aac678",
   "metadata": {},
   "source": [
    "## Set Q, K, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d21c443a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q Parameter containing:\n",
      "tensor([[ 3.3737e-01, -1.7778e-01, -3.0353e-01, -5.8801e-01,  3.4861e-01,\n",
      "          6.6034e-01, -2.1964e-01, -3.7917e-01,  7.6711e-01, -1.1925e+00,\n",
      "          6.9835e-01, -1.4097e+00,  1.7938e-01,  1.8951e+00,  4.9545e-01,\n",
      "          2.6920e-01],\n",
      "        [-7.7020e-02, -1.0205e+00, -1.6896e-01,  9.1776e-01,  1.5810e+00,\n",
      "          1.3010e+00,  1.2753e+00, -2.0095e-01,  4.9647e-01, -1.5723e+00,\n",
      "          9.6657e-01, -1.1481e+00, -1.1589e+00,  3.2547e-01, -6.3151e-01,\n",
      "         -2.8400e+00],\n",
      "        [-1.3250e+00,  1.7843e-01, -2.1338e+00,  1.0524e+00, -3.8848e-01,\n",
      "         -9.3435e-01, -4.9914e-01, -1.0867e+00,  8.8054e-01,  1.5542e+00,\n",
      "          6.2662e-01, -1.7549e-01,  9.8284e-02, -9.3507e-02,  2.6621e-01,\n",
      "         -5.8504e-01],\n",
      "        [ 8.7684e-01,  1.6221e+00, -1.4779e+00,  1.1331e+00, -1.2203e+00,\n",
      "          1.3139e+00,  1.0533e+00,  1.3881e-01,  2.2473e+00, -8.0364e-01,\n",
      "         -2.8084e-01,  7.6968e-01, -6.5956e-01, -7.9793e-01,  1.8383e-01,\n",
      "          2.2935e-01],\n",
      "        [ 5.1463e-01,  9.9376e-01, -2.5873e-01, -1.0826e+00, -4.4382e-02,\n",
      "          1.6236e+00, -2.3229e+00,  1.0878e+00,  6.7155e-01,  6.9330e-01,\n",
      "         -9.4872e-01, -7.6507e-02, -1.5264e-01,  1.1674e-01,  4.4026e-01,\n",
      "         -1.4465e+00],\n",
      "        [ 2.5529e-01, -5.4963e-01,  1.0042e+00,  8.2723e-01, -3.9481e-01,\n",
      "          4.8923e-01, -2.1681e-01, -1.7472e+00, -1.6025e+00, -1.0764e+00,\n",
      "          9.0315e-01, -7.2184e-01, -5.9508e-01, -7.1122e-01,  6.2296e-01,\n",
      "         -1.3729e+00],\n",
      "        [-2.2150e+00, -1.3193e+00, -2.0915e+00,  9.6285e-01, -3.1861e-02,\n",
      "         -4.7896e-01,  7.6681e-01,  2.7468e-02,  1.9929e+00,  1.3708e+00,\n",
      "         -5.0087e-01, -2.7928e-01, -2.0628e+00,  6.3745e-03, -9.8955e-01,\n",
      "          7.0161e-01],\n",
      "        [-9.4053e-01, -4.6806e-01,  1.0322e+00, -2.8300e-01,  4.9275e-01,\n",
      "         -1.4078e-02, -2.7466e-01, -7.6409e-01,  1.3966e+00, -9.9491e-01,\n",
      "         -1.5822e-03,  1.2471e+00, -7.7105e-02,  1.2774e+00, -1.4596e+00,\n",
      "         -2.1595e+00],\n",
      "        [-2.5822e-01, -2.0407e+00, -8.0156e-01, -8.1830e-01, -1.1820e+00,\n",
      "         -2.8774e-01, -6.0430e-01,  6.0024e-01, -1.4053e+00, -5.9217e-01,\n",
      "         -2.5479e-01,  1.1517e+00, -1.7858e-02,  4.2640e-01, -7.6574e-01,\n",
      "         -5.4514e-02],\n",
      "        [-1.2743e+00,  4.5128e-01, -2.2801e-01,  9.2238e-01,  2.0561e-01,\n",
      "         -4.9696e-01,  5.8206e-01,  2.0532e-01, -3.0177e-01, -6.7030e-01,\n",
      "         -6.1710e-01, -8.3339e-01,  4.8387e-01, -1.3493e-01,  2.1187e-01,\n",
      "         -8.7140e-01],\n",
      "        [ 6.8508e-01,  2.0024e+00, -5.4688e-01,  1.6014e+00, -2.2577e+00,\n",
      "         -1.8009e+00,  7.0147e-01,  5.7028e-01, -1.1766e+00, -2.0524e+00,\n",
      "          1.1318e-01,  1.4353e+00,  8.8307e-02, -1.2037e+00,  1.0964e+00,\n",
      "          2.4210e+00],\n",
      "        [ 1.5382e-01, -4.4516e-01,  5.5035e-01,  6.5788e-02,  6.8050e-01,\n",
      "          1.2064e+00,  1.6250e+00,  3.4595e-01,  1.3425e-01,  7.6623e-01,\n",
      "          2.2760e+00, -1.3255e+00, -8.9702e-01,  1.1318e-01,  8.3647e-01,\n",
      "          2.8520e-02],\n",
      "        [-9.7969e-01, -2.1126e+00, -2.7214e-01, -3.5100e-01,  1.1152e+00,\n",
      "         -6.1722e-01, -2.2708e+00, -1.3819e+00,  1.1721e+00, -4.3716e-01,\n",
      "         -4.0527e-01,  7.0864e-01,  9.5331e-01, -1.3035e-02, -1.3009e-01,\n",
      "         -8.7660e-02],\n",
      "        [-6.7349e-02,  2.4674e-01, -9.3917e-01, -1.0448e+00,  1.2783e+00,\n",
      "          4.1903e-01, -5.0727e-01, -6.0623e-01, -1.0532e+00,  1.8386e+00,\n",
      "         -1.0954e-01, -3.3161e-01,  9.0084e-01,  4.8398e-01, -1.3237e+00,\n",
      "          7.8692e-01],\n",
      "        [ 1.3818e+00, -6.9367e-02, -7.6117e-01,  2.4163e-01, -5.8781e-01,\n",
      "         -1.1506e+00,  1.0164e+00,  1.2343e-01,  1.1311e+00, -8.5806e-02,\n",
      "         -5.9727e-02,  3.5527e-01, -1.4355e+00,  7.2748e-02,  1.0528e-01,\n",
      "         -1.0311e+00],\n",
      "        [ 1.3113e+00, -3.5963e-02,  2.1181e-01, -8.6248e-03,  1.8576e+00,\n",
      "          2.1321e+00, -5.0561e-01, -7.9884e-01, -1.0944e+00, -1.0197e+00,\n",
      "         -5.3986e-01,  1.2117e+00, -8.6321e-01,  1.3337e+00,  7.7101e-02,\n",
      "         -5.2181e-02],\n",
      "        [ 2.3862e-01,  1.4106e-01, -1.3354e+00, -2.9340e+00,  1.1411e-01,\n",
      "         -1.2072e+00, -3.0083e-01,  1.4274e-01, -1.3027e+00, -4.9187e-01,\n",
      "         -2.1429e+00,  9.4881e-01, -5.6842e-01, -6.4643e-02,  6.6467e-01,\n",
      "         -2.7836e+00],\n",
      "        [ 1.1366e+00,  9.0886e-01,  9.4943e-01,  2.6565e-02, -9.2207e-01,\n",
      "          7.0338e-01, -3.6590e-01, -1.9654e-01, -9.2071e-01,  3.1535e-01,\n",
      "         -2.1734e-02,  3.4414e-01,  2.2710e-01, -4.5969e-01, -6.1831e-01,\n",
      "          2.4612e-01],\n",
      "        [-4.0549e-01, -8.3681e-01,  1.2277e+00, -4.2971e-01, -2.2121e+00,\n",
      "         -3.7802e-01,  9.8382e-01, -1.0895e+00,  2.0171e-01,  2.2145e-02,\n",
      "         -1.7753e+00, -7.4896e-01,  2.7808e-01, -9.6208e-01, -4.2228e-01,\n",
      "         -1.1036e+00],\n",
      "        [ 2.4727e-01,  1.4549e+00, -2.8351e-01, -3.7675e-01, -3.0577e-02,\n",
      "         -8.9448e-02, -1.9652e-01, -9.7133e-01,  9.0046e-01, -2.5233e-01,\n",
      "          1.0669e+00, -2.9846e-01,  8.5576e-01,  1.6098e+00, -1.1893e+00,\n",
      "          1.1677e+00],\n",
      "        [ 3.2765e-01, -8.3307e-01, -1.6179e+00,  2.2651e-01, -4.3815e-01,\n",
      "          3.2652e-01, -1.5786e+00, -1.3995e+00,  5.4460e-01, -8.3004e-02,\n",
      "         -1.1753e+00,  1.7825e+00,  1.7524e+00, -2.1347e-01,  4.0949e-01,\n",
      "          4.6454e-02],\n",
      "        [ 6.3669e-01, -1.9433e-01, -8.6139e-01,  5.3384e-01,  9.3758e-01,\n",
      "         -9.2248e-01,  7.0466e-01, -2.7221e-01,  1.4419e-02, -6.4115e-01,\n",
      "          2.3902e+00, -1.4256e+00, -4.6192e-01, -1.5539e+00, -3.3382e-01,\n",
      "          2.4049e-01],\n",
      "        [ 2.1065e+00,  5.5087e-01, -2.9364e-01, -1.8027e+00, -6.9333e-01,\n",
      "          1.7409e+00,  2.6979e-01,  9.5949e-01, -1.0253e+00, -5.5049e-01,\n",
      "          1.0264e+00, -5.6696e-01, -2.6584e-01, -1.1116e+00, -1.3696e+00,\n",
      "         -6.5336e-01],\n",
      "        [-1.6125e+00, -2.2840e-01,  1.8388e+00, -9.4727e-01,  1.4192e-01,\n",
      "          3.6959e-01, -1.7425e-02, -9.5746e-01, -8.1691e-01, -2.8655e-01,\n",
      "          4.3434e-01, -1.3402e-01, -2.1467e+00, -1.7984e+00, -6.8222e-01,\n",
      "         -5.1905e-01]], requires_grad=True)\n",
      "Q shape: torch.Size([24, 16])\n",
      "K Parameter containing:\n",
      "tensor([[ 0.0093, -1.8110, -0.2443,  0.1327,  1.0875, -0.1029,  0.8604,  0.2078,\n",
      "          0.2027,  0.5021, -0.4063,  0.6664,  0.4765, -1.4498,  1.5446,  1.0394],\n",
      "        [ 2.1681,  0.4884,  0.3359, -1.2282, -0.1200,  0.4884,  1.9431,  0.2169,\n",
      "         -0.4743, -0.3679, -0.2918, -1.6531,  0.7692, -1.1323,  2.9590,  0.8171],\n",
      "        [ 0.7668,  1.3258,  0.2103,  1.7876, -1.2128,  0.2045,  1.1051, -0.5454,\n",
      "          0.1073,  0.8727, -1.2800, -0.4619,  1.4342, -1.2103,  1.3834,  0.0324],\n",
      "        [ 0.5421,  0.8796,  0.2713,  1.6067, -1.0004,  0.7392, -0.4931,  0.4073,\n",
      "         -1.0394, -0.3226,  0.7226,  0.2674, -0.4673,  0.6916, -1.8752,  0.3008],\n",
      "        [-0.1468,  1.3672,  0.7074,  0.3276,  1.0658,  1.4130, -1.2445,  0.2227,\n",
      "          0.4593, -0.3845,  0.6554, -0.1045, -1.1134,  0.5110,  0.3566,  1.8591],\n",
      "        [-0.9300,  1.1186,  1.7495,  2.3058,  0.3734,  0.3314, -0.1871,  0.1770,\n",
      "          2.9641,  0.2307,  0.3228,  0.2610,  0.3219,  1.7745,  0.3155, -0.9364],\n",
      "        [ 0.5687, -0.0959,  0.0046, -1.4321, -0.1535, -0.1925, -0.3115, -0.1812,\n",
      "         -0.8745, -0.0270,  0.5424,  1.3656, -0.0284, -0.7411, -0.0169,  1.7024],\n",
      "        [ 0.4206,  0.9317,  0.9884, -0.3948,  0.6919,  1.2310, -0.5126, -1.2635,\n",
      "          1.1440,  0.7619,  0.6543, -1.5402, -0.5176, -0.0315, -1.0640,  0.9417],\n",
      "        [-1.3152, -0.0677, -0.1350, -0.5183,  0.2326,  1.6311, -0.8707,  0.0490,\n",
      "         -0.2526,  0.0810,  1.2702,  0.7397,  1.0890, -0.6591, -0.1910,  0.5061],\n",
      "        [ 1.7788, -0.7092, -1.5262, -1.4693,  3.2052, -0.2765, -0.0540,  0.6673,\n",
      "         -0.5023, -1.1043,  0.8741, -1.4747, -0.0785, -0.9214, -1.2015, -0.1640],\n",
      "        [ 1.1366, -0.7330,  1.3382,  0.2706,  0.5071,  0.0171, -0.3081, -1.1696,\n",
      "         -0.4264, -0.9266,  0.4074, -0.0637, -1.4105, -1.1709, -1.0945, -0.3700],\n",
      "        [-0.0037,  0.6299,  0.5173,  0.6031, -1.0045,  0.1959,  1.4460, -2.4599,\n",
      "         -0.7120, -1.7431,  0.0511, -0.2768, -0.6183,  0.4465,  2.0123, -2.3251],\n",
      "        [ 1.2701, -0.5276,  0.9680,  0.6084,  0.2185, -1.9706, -0.6639, -0.0259,\n",
      "          1.2727, -0.7957,  0.1192, -0.8141,  0.1331,  0.2122, -0.8834,  0.2889],\n",
      "        [ 0.2049,  0.8829, -0.9549, -0.8661,  1.5936,  1.6861, -0.3435,  0.7307,\n",
      "          0.5862,  0.6368, -0.9336, -0.5557, -0.1931, -0.1619, -1.5147, -2.4497],\n",
      "        [-1.4778,  0.5976, -0.0499, -0.3470, -0.3891,  1.8949,  0.2074,  0.4183,\n",
      "          0.6459, -0.9409, -0.2496, -0.7737,  0.0753,  0.5233,  0.6921,  0.2203],\n",
      "        [-0.7465,  0.2230,  0.0099, -0.6379, -1.7189,  1.4508,  0.9371, -1.8408,\n",
      "          0.5539,  1.9170, -0.6074, -0.7221,  2.5328, -1.2669,  1.1882,  0.1221],\n",
      "        [-1.1065,  1.2682,  0.3147, -0.9990, -0.5298, -1.1257, -1.5839,  0.1298,\n",
      "          1.8622, -0.7446,  0.3587,  0.8623,  0.9155,  1.0884,  0.7310, -0.5469],\n",
      "        [-1.8025, -0.5228,  0.8150, -0.1398,  0.6961,  0.3076, -1.1440, -0.5357,\n",
      "         -0.3139,  0.7074, -0.9846,  0.2325, -0.5109, -1.0550,  0.0795,  1.2257],\n",
      "        [ 1.7500, -0.2029, -0.6854,  1.4270, -0.3253,  0.7013, -0.1262, -1.2932,\n",
      "          0.4858,  1.1693,  0.2187, -0.9539,  1.2004,  2.7040,  0.0263,  0.5223],\n",
      "        [ 0.3042, -1.1535, -1.6998,  0.7063, -0.2409,  0.3416, -1.3678, -1.1215,\n",
      "         -0.3553,  0.3365, -0.1046, -0.4144, -0.3990,  0.4466, -0.8970,  0.1009],\n",
      "        [ 0.2344, -1.9974, -1.3085, -0.0303, -0.1969, -1.5757,  0.0429, -1.3116,\n",
      "          0.5660, -1.1568, -0.9462, -0.8255,  0.2688,  0.0654,  0.3776, -0.3426],\n",
      "        [ 0.5645,  1.0475,  2.1908, -0.6795, -0.2195,  1.0675, -0.1212,  0.2905,\n",
      "          1.0915,  2.0949, -1.7970, -0.7727,  0.7943,  0.0482, -0.5971,  0.7392],\n",
      "        [-0.0924, -0.1438,  0.8288, -1.3547,  0.9202,  0.1743, -0.4796, -0.0736,\n",
      "         -0.0419, -0.0535,  1.2129,  0.1204,  0.7503, -0.1014,  1.3939, -0.3851],\n",
      "        [ 0.2364,  0.9211,  0.1316,  0.4803, -1.1292,  1.0720,  1.1054, -2.0586,\n",
      "          0.2878, -1.1389,  0.1729,  0.9646,  0.8133, -0.3181, -1.3936,  0.5226]],\n",
      "       requires_grad=True)\n",
      "K shape: torch.Size([24, 16])\n",
      "V Parameter containing:\n",
      "tensor([[ 2.5787e-01,  3.4197e-01, -8.1678e-01,  1.6772e+00, -8.3530e-01,\n",
      "          7.5313e-01,  8.2088e-02,  1.1650e+00, -6.6353e-01, -7.8086e-01,\n",
      "         -2.2698e-01, -4.3579e-01,  8.2092e-01, -6.3535e-01, -4.3858e-01,\n",
      "         -4.4725e-01],\n",
      "        [ 1.5098e+00, -7.8324e-02,  7.7068e-01,  5.1801e-01,  2.4576e-01,\n",
      "          3.9369e-01, -7.8823e-01,  3.2278e-01, -7.4468e-01,  3.1022e-01,\n",
      "         -1.4619e+00, -1.7453e-01, -5.4822e-01, -4.0971e-01, -6.2742e-02,\n",
      "          1.7471e-02],\n",
      "        [ 1.3715e+00, -2.2264e-01,  1.0566e+00,  3.6867e-01,  1.8359e+00,\n",
      "          1.2957e+00,  8.0446e-01, -6.1880e-01, -1.1795e+00,  3.3830e-01,\n",
      "          9.3189e-01,  7.4360e-01,  2.4900e-01, -1.3814e+00, -7.9847e-01,\n",
      "          6.3693e-01],\n",
      "        [-1.5530e+00, -1.6292e+00,  6.1071e-01,  1.2718e+00, -9.4217e-01,\n",
      "         -2.6674e-01, -3.2164e-01,  4.5042e-01,  3.7180e-01,  6.4572e-01,\n",
      "          5.8042e-01,  3.7519e-01,  4.2925e-01, -7.2756e-01, -5.5272e-01,\n",
      "          6.1892e-01],\n",
      "        [-1.4284e+00,  5.6165e-01,  7.7010e-01,  3.5661e-01, -1.2674e-01,\n",
      "          9.4469e-01,  1.4664e-01,  2.6728e-01,  9.4674e-01, -1.4060e-01,\n",
      "          3.2859e-02, -2.1542e+00,  1.3953e+00,  1.1845e+00, -1.2553e-01,\n",
      "          2.5165e-01],\n",
      "        [ 1.3081e+00,  1.4954e-01,  1.1315e+00,  2.0443e-01,  1.2430e+00,\n",
      "         -4.0931e-02,  7.4906e-01,  3.0262e-01, -7.5907e-01, -9.5420e-01,\n",
      "         -1.6160e+00, -1.0162e-01, -1.1510e+00, -1.8215e+00,  1.1655e+00,\n",
      "         -2.3307e+00],\n",
      "        [ 5.0618e-01, -1.5363e+00, -6.1260e-01,  1.7107e+00,  3.0738e-01,\n",
      "          5.1980e-01,  7.9984e-01,  1.8777e+00,  1.0335e+00,  3.0392e-01,\n",
      "          1.0032e+00,  2.8644e-01,  1.0715e-01,  3.3115e-01,  4.0457e-01,\n",
      "          1.3129e+00],\n",
      "        [-1.1463e-01, -1.3176e+00,  7.0748e-01,  2.5455e-01, -2.8901e-01,\n",
      "         -2.1409e-01,  1.3640e+00, -6.0771e-01,  1.0385e+00, -2.1864e+00,\n",
      "          1.4807e-01, -8.4771e-01,  7.7293e-01, -1.3574e+00, -1.1745e+00,\n",
      "         -5.1264e-01],\n",
      "        [ 1.5811e-01,  9.0645e-01, -1.8441e+00,  1.9309e-01, -2.1604e+00,\n",
      "          2.3336e-01,  2.1485e-02,  1.8687e+00,  2.8131e-02,  2.2443e-01,\n",
      "          1.3499e+00,  2.0415e-01,  5.6420e-01, -4.4783e-01, -9.9623e-01,\n",
      "          5.4181e-01],\n",
      "        [-6.2749e-01,  2.4954e-01,  6.2411e-01,  1.4557e+00,  1.3382e+00,\n",
      "         -1.1949e-01,  1.1260e+00,  2.7520e-01, -7.2587e-01,  4.4239e-01,\n",
      "          1.1071e-01,  7.3145e-01, -2.3556e-01,  2.7213e+00, -1.0219e+00,\n",
      "          4.8787e-01],\n",
      "        [-1.8278e+00, -6.4393e-01,  8.1895e-01,  4.0578e-02,  5.7499e-01,\n",
      "         -3.9772e-01, -9.8528e-01, -6.1831e-01,  1.6453e+00,  1.9893e-01,\n",
      "         -1.1784e+00,  6.6541e-03,  6.0126e-01, -8.5485e-01,  5.1528e-01,\n",
      "          5.3092e-01],\n",
      "        [-5.5185e-01,  8.6607e-01,  1.6997e-01,  1.9798e+00, -1.2099e+00,\n",
      "          7.1287e-02,  8.2581e-01, -2.6191e-02,  9.9540e-01,  2.3472e+00,\n",
      "         -1.1227e-01, -3.6618e-01, -1.0509e+00, -6.7348e-01, -5.7630e-01,\n",
      "         -9.2912e-01],\n",
      "        [-7.7692e-01, -1.3758e+00, -4.3485e-02,  2.9571e+00, -1.2452e+00,\n",
      "          7.6677e-01, -1.3397e+00, -5.8200e-01,  3.3147e+00, -7.8773e-01,\n",
      "          6.6130e-02,  2.9956e+00,  1.6833e-01, -1.5272e-01,  1.3114e-02,\n",
      "         -2.3113e-01],\n",
      "        [ 1.0955e+00, -5.6462e-01,  8.9680e-01, -4.6015e-01,  1.5772e+00,\n",
      "          2.7433e+00,  2.7943e+00, -7.7758e-01,  3.9030e-01, -3.3310e-01,\n",
      "         -9.2882e-01, -2.9780e-01,  2.0895e-01, -3.2553e-01,  5.8636e-01,\n",
      "         -6.1214e-01],\n",
      "        [-2.6970e+00, -2.5137e-01, -8.9171e-01,  8.2555e-01,  9.5923e-01,\n",
      "         -1.5753e+00, -6.8132e-01, -4.1813e-01,  2.5726e-01,  6.9367e-01,\n",
      "          4.2067e-01,  1.0646e+00, -2.2300e-02,  5.8324e-01, -1.2162e+00,\n",
      "         -1.0512e+00],\n",
      "        [-4.3006e-01,  9.3392e-01, -4.7223e-01,  8.5099e-01,  1.9905e-01,\n",
      "          7.7871e-01, -6.9981e-01,  3.8745e-02, -1.8313e+00, -5.1683e-02,\n",
      "         -3.4498e-02, -6.4643e-01, -3.5806e-01, -4.8396e-01, -2.7128e-01,\n",
      "         -7.7399e-02],\n",
      "        [ 5.2290e-01,  1.5533e-01,  5.2474e-01, -4.9166e-01,  5.1030e-01,\n",
      "         -7.7296e-01, -3.4119e-01,  1.4254e+00, -6.9474e-02, -1.6288e-01,\n",
      "         -1.3837e+00,  6.1889e-01, -3.0485e+00, -1.0450e+00,  8.4340e-01,\n",
      "          1.8587e+00],\n",
      "        [-3.9299e+00,  3.4351e-01, -1.1167e+00, -7.7037e-01,  1.6089e-01,\n",
      "         -7.2442e-01,  5.4321e-02, -9.6648e-01,  6.3635e-01, -6.9496e-02,\n",
      "         -8.0825e-01, -6.5679e-03, -3.5904e-01,  3.1714e-01, -8.5288e-01,\n",
      "         -1.4709e+00],\n",
      "        [-3.7307e-01,  2.2988e-01,  1.6853e+00, -3.0724e-01, -8.8742e-02,\n",
      "          1.2282e-01,  8.2266e-01, -1.1443e+00, -1.0932e+00,  5.1557e-01,\n",
      "          1.0474e+00,  4.4523e-01,  1.5324e+00,  2.8387e-02, -9.6249e-01,\n",
      "         -3.9615e-01],\n",
      "        [-1.0612e+00,  1.3935e+00, -5.5944e-01, -3.8827e-01, -3.3504e-01,\n",
      "         -8.5009e-01, -1.8178e+00,  7.2969e-01,  1.2289e+00, -8.7367e-01,\n",
      "          6.2854e-01,  7.9055e-01, -4.1467e-01,  2.0388e+00, -1.8956e-02,\n",
      "         -6.9371e-01],\n",
      "        [ 4.1730e-01,  1.0526e+00, -4.1566e-01, -1.6411e-03, -5.0299e-01,\n",
      "          7.0110e-01,  1.8256e+00,  4.2742e-02, -3.0871e-01,  1.4557e+00,\n",
      "         -5.6832e-01,  9.8822e-01,  1.5823e+00, -1.1659e+00,  1.3834e-01,\n",
      "         -9.8013e-01],\n",
      "        [ 1.0355e+00,  3.2153e-01, -2.8673e-01,  2.0399e+00,  1.3400e-03,\n",
      "         -7.1740e-01, -3.7461e-01,  3.1536e-02, -1.0315e+00, -8.7508e-01,\n",
      "         -1.7115e+00,  5.6722e-01, -6.4333e-01, -1.7113e+00, -5.0015e-01,\n",
      "         -7.5509e-01],\n",
      "        [ 5.3442e-01, -2.2221e+00, -4.3297e-01,  9.6336e-01,  1.2769e+00,\n",
      "          1.0020e+00,  1.5851e-01,  4.0664e-01,  1.5587e+00, -1.8793e-01,\n",
      "          1.2295e+00, -5.1313e-01, -2.5615e-01,  2.0386e-01, -2.1254e+00,\n",
      "          8.8885e-01],\n",
      "        [ 8.3930e-01, -8.2973e-02, -2.5591e-01, -3.0097e-01,  2.7265e-01,\n",
      "          1.5576e+00, -4.0840e-01,  1.1356e-01, -1.2418e+00,  3.9737e-01,\n",
      "          2.4015e+00,  2.8180e-01, -4.2874e-01,  9.4270e-01,  1.1394e+00,\n",
      "          1.0076e+00],\n",
      "        [-1.0693e+00,  4.6599e-01,  7.0121e-01, -1.7983e+00, -3.0257e-01,\n",
      "         -3.7281e-01,  1.7021e+00, -1.7532e-01, -2.0416e+00, -2.7491e-01,\n",
      "          1.5302e+00, -4.5480e-01, -6.5086e-01,  8.5893e-01, -6.9792e-01,\n",
      "          1.4601e-01],\n",
      "        [ 1.2517e+00, -1.2915e+00,  2.3187e-01,  2.8986e-01,  9.9813e-01,\n",
      "         -1.4029e+00, -3.1931e-01, -1.4520e+00, -7.0100e-01, -9.4900e-01,\n",
      "          6.8880e-01, -8.7413e-01,  5.3157e-01, -1.9083e+00,  4.0456e-01,\n",
      "          8.2641e-01],\n",
      "        [ 2.3255e-01, -2.9999e-01, -3.8346e-01, -3.6891e-01,  1.2539e+00,\n",
      "         -3.5398e-02,  3.5245e-01, -1.2732e+00, -4.3232e-01,  1.3087e+00,\n",
      "         -5.2600e-01, -2.6090e+00,  4.1604e-01, -4.0767e-01,  6.5081e-01,\n",
      "          1.4137e+00],\n",
      "        [ 5.6002e-01,  1.7931e+00,  6.1939e-02, -9.1584e-01,  1.6036e+00,\n",
      "         -4.1183e-01,  9.5650e-01,  1.1037e+00, -1.1292e+00,  4.5102e-01,\n",
      "          5.4735e-01,  1.6674e+00,  3.9591e-01,  2.7196e+00,  4.8159e-01,\n",
      "          2.4091e-01]], requires_grad=True)\n",
      "V shape: torch.Size([28, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "d = embedded_sentence.shape[1]  # d = embedding dimension\n",
    "d_q, d_k, d_v = 24, 24, 28\n",
    "\n",
    "# Parameter is a special kind of tensor which are auto assigned to Module.parameters iterator\n",
    "# This allows us to pass the parameters to an optimizer so they can be updated during training\n",
    "# Also it auto-sets the Tensor.requires_grad=True flag so we can use them in training\n",
    "Q = torch.nn.Parameter(torch.randn(d_q, d)) \n",
    "K = torch.nn.Parameter(torch.randn(d_k, d))\n",
    "V = torch.nn.Parameter(torch.randn(d_v, d))\n",
    "\n",
    "print()\n",
    "print(f\"Q {Q}\")\n",
    "print(f\"Q shape: {Q.shape}\")\n",
    "print(f\"K {K}\")\n",
    "print(f\"K shape: {K.shape}\")\n",
    "print(f\"V {V}\")\n",
    "print(f\"V shape: {V.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0543ce3f",
   "metadata": {},
   "source": [
    "## Computing unnormalized attention weights (aka scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da479df8",
   "metadata": {},
   "source": [
    "### Sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a395238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n",
      "torch.Size([24])\n",
      "torch.Size([24])\n",
      "torch.Size([28])\n"
     ]
    }
   ],
   "source": [
    "x_2 = embedded_sentence[1]\n",
    "print(x_2.shape)\n",
    "query_2 = Q.matmul(x_2) # query_2 = Q @ x_2  # this is equivalent to the above line\n",
    "key_2 = K.matmul(x_2)\n",
    "value_2 = V.matmul(x_2)\n",
    "\n",
    "print(query_2.shape)\n",
    "print(key_2.shape)\n",
    "print(value_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a108b",
   "metadata": {},
   "source": [
    "### Calculate all attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82e28956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys shape: torch.Size([6, 24])\n",
      "Values shape: torch.Size([6, 28])\n"
     ]
    }
   ],
   "source": [
    "keys = K.matmul(embedded_sentence.T).T  # keys.T = K @ embedded_sentence.T\n",
    "values = V.matmul(embedded_sentence.T).T  # values.T = V @ embedded_sentence.T\n",
    "\n",
    "print(f\"Keys shape: {keys.shape}\")\n",
    "print(f\"Values shape: {values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb7c183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
