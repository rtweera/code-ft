{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "390f1c7c",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7591fd",
   "metadata": {},
   "source": [
    "This is a simulation of the tokenization process. The goal is to take a string of text and break it down into smaller pieces, or tokens. This is often the first step in natural language processing (NLP) tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9926eab",
   "metadata": {},
   "source": [
    "### Input sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a318fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Life is short, eat dessert first'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f0b58",
   "metadata": {},
   "source": [
    "### Simulating the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c543ffa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}\n"
     ]
    }
   ],
   "source": [
    "vocabulary = {s:i for i,s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b87e46e",
   "metadata": {},
   "source": [
    "### Tokenization Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca95c70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 4, 5, 2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sentence_int = torch.tensor([vocabulary[s] for s in sentence.replace(',', '').split()])\n",
    "print(sentence_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7611bc84",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffc2e14",
   "metadata": {},
   "source": [
    "Create vector embeddings for the tokens. Each token is represented as a 16-dimensional vector. Since we have 6 tokens, we will create a 6x16 matrix. The values in the matrix are randomly generated for the purpose of this simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,\n",
      "          0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951,  0.4954,  0.2692],\n",
      "        [ 0.5146,  0.9938, -0.2587, -1.0826, -0.0444,  1.6236, -2.3229,  1.0878,\n",
      "          0.6716,  0.6933, -0.9487, -0.0765, -0.1526,  0.1167,  0.4403, -1.4465],\n",
      "        [ 0.2553, -0.5496,  1.0042,  0.8272, -0.3948,  0.4892, -0.2168, -1.7472,\n",
      "         -1.6025, -1.0764,  0.9031, -0.7218, -0.5951, -0.7112,  0.6230, -1.3729],\n",
      "        [-1.3250,  0.1784, -2.1338,  1.0524, -0.3885, -0.9343, -0.4991, -1.0867,\n",
      "          0.8805,  1.5542,  0.6266, -0.1755,  0.0983, -0.0935,  0.2662, -0.5850],\n",
      "        [-0.0770, -1.0205, -0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010,\n",
      "          0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255, -0.6315, -2.8400],\n",
      "        [ 0.8768,  1.6221, -1.4779,  1.1331, -1.2203,  1.3139,  1.0533,  0.1388,\n",
      "          2.2473, -0.8036, -0.2808,  0.7697, -0.6596, -0.7979,  0.1838,  0.2293]])\n",
      "torch.Size([6, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)  # embedding initialization is random, so we set a seed for reproducibility\n",
    "embed = torch.nn.Embedding(6, 16)\n",
    "embedded_sentence = embed(sentence_int).detach()\n",
    "\n",
    "print(embedded_sentence)\n",
    "print(embedded_sentence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea43862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
