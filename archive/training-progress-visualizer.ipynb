{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d08ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, TrainerCallback\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, update_display, HTML\n",
    "\n",
    "class ProgressVisualizationCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.training_logs = []\n",
    "        self.output_id = 'progress_viz'\n",
    "        self.fig = None\n",
    "    \n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        self.training_logs = []\n",
    "        # Don't print anything here to avoid interfering with the default progress display\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs:\n",
    "            self.training_logs.append(logs)\n",
    "            # Plot every 10 logs to avoid slowing down training\n",
    "            if len(self.training_logs) % 10 == 0:\n",
    "                self.visualize_progress(state)\n",
    "    \n",
    "    def visualize_progress(self, state):\n",
    "        # Extract metrics\n",
    "        steps = [log.get('step', i) for i, log in enumerate(self.training_logs) if 'loss' in log]\n",
    "        loss = [log['loss'] for log in self.training_logs if 'loss' in log]\n",
    "        lr = [log['learning_rate'] for log in self.training_logs if 'learning_rate' in log]\n",
    "        \n",
    "        # Create plot\n",
    "        if self.fig is None:\n",
    "            self.fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            display(self.fig, display_id=self.output_id)\n",
    "        else:\n",
    "            # Clear previous plot data\n",
    "            for ax in self.fig.axes:\n",
    "                ax.clear()\n",
    "            ax1, ax2 = self.fig.axes\n",
    "        \n",
    "        # Loss plot\n",
    "        ax1.plot(steps, loss, label='Training Loss')\n",
    "        ax1.set_xlabel('Step')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.set_title('Training Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # Learning rate plot\n",
    "        ax2.plot(steps, lr, label='Learning Rate', color='green')\n",
    "        ax2.set_xlabel('Step')\n",
    "        ax2.set_ylabel('Learning Rate')\n",
    "        ax2.set_title('Learning Rate Schedule')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        self.fig.tight_layout()\n",
    "        update_display(self.fig, display_id=self.output_id)\n",
    "        \n",
    "        # Don't print status here to avoid interfering with the default progress display\n",
    "\n",
    "# Setup training with proper logging\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,  # Log every 10 steps\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,    # Evaluate every 100 steps\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,    # Save model every 100 steps\n",
    "    save_only_model=True,  # Only save model weights, not optimizer state\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    max_steps=1000,    # Set a specific number of steps\n",
    "    report_to=\"none\",  # Disable wandb/tensorboard to avoid conflicts\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Create the trainer with our callback\n",
    "progress_callback = ProgressVisualizationCallback()\n",
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[progress_callback],  # Add the callback here\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "resource_monitor = ResourceMonitor(interval=60, log_path=\"training_log.csv\", verbose=False)\n",
    "resource_monitor.start(append_log=True)\n",
    "trainer.train()\n",
    "resource_monitor.stop()\n",
    "print(\"Training completed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
